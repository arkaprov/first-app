Setting hostname - sudo hostnamectl set-hostname <new_hostname>
Github push repo to github


1. Yum install git -y
2. ssh-keygen
3. Cd .ssh
4. Copy the public key, now add this in github
5. Cd data/
6. git init
7. git add .
8. git commit -m "Initial commit"
9. git remote add origin git@github.com:arkaprovolti/first-app.git
10. git remote -v
11. git push  origin master
12. 

Github: cloning same repo and pushing it to same repo;
1. git clone git@github.com:arkaprovolti/first-app.git
2. cat > sds.txt
sdaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa yeyyy
3. git add .
4.  git commit -m "Initial commit"
5. git push  origin main




Github- cloning a different repo and pushing it to my repo
1. git clone git@github.com:sanjayguruji/java-code-with-maven.git
2. Now go inside /java-code-with-maven directory cloned
3. git remote -v
4. git remote set-url origin git@github.com:arkaprovolti/java-maven-arka-2.git
5. Git push origin main


Jenkins
1. 15 gb gp2 instance
2.  yum update -y
3. Google search installing jenkins on aws
4. sudo wget -O /etc/yum.repos.d/jenkins.repo \
https://pkg.jenkins.io/redhat-stable/jenkins.repo
5. Yum repolist all
6. sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key
sudo yum upgrade
7. Instance -> security groups -> select your one -> edit inbound rules ->add custom tcp -> port range 8080 -> 0.0.0.0/0
8. Now copy public ip : 8080
9. sudo yum install java-17-amazon-corretto -y
10. Sudo yum install jenkins -y
11. Systemctl enable jenkins
12. Systemctl start jenkins
13. Open public ip of server
14. Paste vim  /var/lib/jenkins/secrets/initialAdminPassword and unlock jenkins
15. Now gotta increase size of temp
16. sudo mount -o remount, size=2G /tmp
17. df -h
18. vim /etc/fstab
19. tmpfs /tmp tmpfs defaults,noatime,mode=1777,size=2G 0 0
20. Sudo mount -a
21. Systemctl daemon-reload
22. Reboot instance
23. in case if ec2 instance is shutdown, jenkins node will go slow. To solve this, go to
Cd /var/lib/jenkins -> jenkins.model…….xml -> open it in vim -> we got an ip address, replace it with port ip.
24. Now we gotta integrate jenkins server with our github repo.
25. Add webhooks in our github repo
26. Payload url should look like http://51.20.118.218:8080/github-webhook/
27. You gotta get secret, for this go to jenkins -> security -> create api token, githooks -> allow on agents.
28. Now we will make a pipeline in jenkins -> new item -> freestyle ->ok
29. Go to configure, of the created pipeline, and paste repo url in htpps
30. yum install git
31. Now build pipeline


Tomcat server setup
   1. yum install java -y
yum install wget
wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.108/bin/apache-tomcat-9.0.108.tar.gz
tar -xvzf apache-tomcat-10.1.44.tar.gz
mv apache-tomcat-10.1.44.tar.gz /tmp
 cd apache-tomcat-10.1.44
cd bin/
chmod +x startup.sh
chmod +x shutdown.sh
cd ..
cd apache-tomcat-10.1.44
find -name context.xml -> 3 files be created -> now we gotta last 3 run each of em in vim
vim ./webapps/examples/META-INF/context.xml
cd conf
vim tomcat-users.xml
push given lines between --> and </tomcat-users>: 
    <role rolename="manager-gui"/>
<role rolename="manager-script"/>
<role rolename="manager-jmx"/>
<role rolename="manager-status"/>   
<user username="admin" password="admin" roles="manager-gui,manager-script,manager-jmx,manager-status"/>
<user username="deployer" password="deployer" roles="manager-script"/>
<user username="tomcat" password="s3cret" roles="manager-gui"/>

cd bin
./startup.sh

Instance -> security groups -> select your one -> edit inbound rules ->add custom tcp -> port range 8080 -> 0.0.0.0/0
Now copy public ip : 8080





Integrating java GitHub repo with Jenkins (after Jenkins server is setup)

yum install git -y
yum install maven -y
mvn -v  --> can see maven hom path and java path
Now you gotta install plugins - maven integration, deploy to container, GitHub integration
Now restart Jenkins
Now you gotta path set -> Manage Jenkins -> Tools -> add jdk ->java path -> maven- maven path
Now we gotta integrate jenkins server with our github repo.
26. Payload url should look like http://51.20.118.218:8080/github-webhook/
27. You gotta get secret, for this go to jenkins -> security -> create api token, githooks -> allow on agents.
Now new build -> maven project -> git repo https paste -> untick snapshot -> apply and save












Launching index.html on httpd server

1. Launch an ec2 instance
yum install httpd -y
rpmquery httpd
cd /var/www/html
 cat > index.html
give port no.80 
systemctl start httpd
systemctl enable httpd
http://54.235.42.184/:80


Making AMI of instance
1. go to your instance
actions -> image ->create image.
the ami will be created in ami catalog -> my ami
Now launch instance with AMI
Create instance
You will see the same machine content will be copied into a different machine
Now you want to share this AMI for a different account, so go to AMI -> Shared account id ->add account id
Now that account id can see your AMI into his, he can make instance of that and the files will be shared.









Creating a template and launching 2 instances

Ec2->Launch templates -> Create new template -> My AMIS -> owned by me ->  EBS Volume 10gb gp2
Go to a instance -> Launch instance from template
Now I want script automatically triggered -> Advanced Settings -> User Data ->
	yum install httpd -y
	cat > index.html
	systemctl start httpd
	systemctl enable httpd
	useradd John
	passwd John
create launch template
Now, go to an instance and launch instance from template -> give no. of instances 2 -> launch instance
Now we can see 2 instances loaded for the given templat -> You can see if public ip is pasted with port 80 (make sure to configure port 80 in inbound rules)

We can modify template by launching template -> Modify template





Creating Volume in an instance

1. lsblk
2. Now we will create 5 gb volume -> EC2 -> volume -> 5GB
3. Now tick the created volume -> actions -> attach volume -> attach our created instance -> give a device ->
4. lsblk -> we can see our new volume now
5. Now how to access our new disk??
6. lsblk -fs -> we can't see our 5 gb created volume.
7. blkid -> This will show our UUID
8. mkdir /data
9. mount /dev/xvdb /data
df -h
cd /data/
touch Sanjaya.txt{1....100} ->100 blank files created
ll
Now temporary mounting is done. For permanent mounting, we have to follow next steps.
You can get uiid from blkid
vim /etc/fstab -> write
	/dev/xvdb	/data	ext4	defaults 0 0
Restart instance


Extending root volume of an instance

1. Launch an instance
2. create an httpd server
yum install httpd -y
rpmquery httpd
cd /var/www/html
 cat > index.html
give port no.80 
systemctl start httpd
systemctl enable httpd
curl http://localhost -> now the server is live
df -h -> we can see /dev/xvda1 is 10 Gb, which isn't enough for us en, we gotta increase its volume
Now go to volume -> select the volume of the created instance -> modify volume
Now change size to 20 gb
df -h -> but still 10 gb is visible in /dev/xdva1 because OS can read only that storage which have filesystem
So google how to extend xfs filesystem in rhel 8 in aws ec2
growpart /dev/xvda1
growpart /dev/xvda 1
sudo xfs_growfs -d /
df -h -> Now /dev/xvda1 size is increased to 20 gb





Creating a new volume and attaching it with our instance, and also make 2 partitions of this new volume

Create new volume - 7gb, attach it with our instance
fdisk -l
Now, for partitioning we'll use MS DOS Partition scheme
lsblk
fdisk /dev/xvdb
m
n
e
4
 give both sector empty
p
lsblk -> xvdb5 and xvdb6 created we can see
fdisk -l
Now we gotta create mount point. We can use either ext4 or xfs filesystem for xvdb5 and xvdb6 partition.
Now create 2 directories, and mount both in these directories.
mkdir /devops
mkdir /data
mount /dev/xvdb5 /data/
mount /dev/xvdb6 /devops/
cd /devops
touch arka.txt{1...5}

Now if we wanna unmount them and detach them from cloud, and then delete the volume
umount /devops
umount /data





Data replicate in ec2 into different region same zone

1. HW given ->  Data replicate in ec2 into same region different zone
For this we have to use snapshot. It inherits all zones of our region. Snapshot is stored in AWS S3 in backend, but not reachable for us.
2. Our Volume -> create snapshot -> create snapshot
3. Now choose different region and go to snapshot (Ohio - us-east-1b) -> not reachable. Because Snapshot is a region based service. Now copy snapshot and choose us-east-2.




Data replicate in ec2 into same region different zone

For this we have to use snapshot. It inherits all zones of our region. Snapshot is stored in AWS S3 in backend, but not reachable for us.
2. Our Volume -> create snapshot -> create snapshot
3. Now for the created snapshot -> we create volume from snapshot and choose a different region.
Now create an instance for that volume


Data replication in EFS by 3 different machines in 3 different zones in same region

1. Create 3 instances 8 gb each (amazon Linux, redhat, ubuntu) in 3 different regions
2. Same security group with all 3 machines
3. Search EFS -> create file system 
4. For the file system created -> view ->edit
We gotta install nfs in all of 3 machines (nfs is by default installed in amazon Linux)
amazon machine -> rpmquery nfs-utils
		systemctl start nfs-server.service
		systemctl enable nfs-server.service
		systemctl status
redhat -> 
	yum install nfs-utils -y
	systemctl start nfs-server.service
		systemctl enable nfs-server.service
		systemctl status

ubuntu ->
	apt update -y
	apt install nfs-common
	systemctl start nfs-utils.service
	systemctl enable nfs-utils.service
we went to security group and added nfs.
Now go EFS -> file systems -> network -> managet -> security group changed to nfs - a,b,c keep ; deleted rest.
Now we go to our filesystem -> Attach -> Mount via DNS -> copy "using the NFS client" ->
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-034ce5eaefe890aad.efs.us-east-1.amazonaws.com:/ efs

now we create a directory (data) on either machine in root (for easy), paste the copied sudo mount... and replace efs with our directory.


Now we create another directory in another machine, and paste sudo mount ... and replace efs with our directory, create files in there -> touch fk.txt{1..10}

Now, in our previous mounted machine, in the mounted directory, we can find our files created in previous machine.







